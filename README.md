# ONE BILLION ROWS CHALLENGE - PYTHON EDITIONüêç

## ABOUT THE PROJECT

‚ú® Uma jornada pr√°tica de engenharia de dados para processar 1 bilh√£o de registros, extraindo estat√≠sticas agregadas de temperatura com performance, escalabilidade em Python, utilizando o projeto One Billion Row Challenge, desenvolvido como um exerc√≠cio avan√ßado de engenharia de dados aplicada, com o objetivo de demonstrar como processar com efici√™ncia um arquivo massivo de 1 bilh√£o de linhas (~14GB) usando Python, cujo foco est√° em realizar opera√ß√µes computacionalmente simples, como agrega√ß√µes (m√≠nimo, m√©dia e m√°ximo) e ordena√ß√£o com uso de recursos computacionais, de forma escal√°vel.

Como complemento visual e anal√≠tico, o projeto inclui um dashboard interativo desenvolvido em Streamlit, com car√°ter de portfolio, sem utiliza√ß√£o pr√°tica, que consome os dados processados e permite ao usu√°rio explorar visualmente as estat√≠sticas por esta√ß√£o meteorol√≥gica, cujo painel apresenta uma tabela din√¢mica com os dados agregados, gr√°ficos de barras para temperatura m√©dia, m√≠nima e m√°xima, al√©m de um gr√°fico de dispers√£o cruzando extremos t√©rmicos, tudo isso com visualiza√ß√£o responsiva e performance local, sem necessidade de infraestrutura em nuvem.

Este projeto √© particularmente √∫til como estudo de caso para engenheiros de dados, cientistas de dados e desenvolvedores que desejam aprofundar seus conhecimentos em processamento de arquivos massivos, estrat√©gias de chunking, desempenho de bibliotecas Python e uso de engines anal√≠ticas modernas como o DuckDB, e embora o One Billion Row Challenge n√£o seja um projeto t√©cnico, ele simula situa√ß√µes reais de neg√≥cio enfrentadas por empresas que lidam com grandes volumes de dados transacionais, sensoriais ou operacionais.

Todo o desafio foi executado em um ambiente local (homelab), utilizando um Dell Optiplex 7020, com sistema operacional Ubuntu Server, processador Intel Core i5-14500T e 16 GiB de mem√≥ria RAM.

## INSPIRATION

O desafio foi inspirado no projeto original [1BRC](https://github.com/gunnarmorling/1brc), proposto por Gunnar Morling, em Java, posteriormente, a iniciativa foi adaptada para Python por Luciano Vasconcelos, no reposit√≥rio [One-Billion-Row-Challenge-Python](https://github.com/lvgalvao/One-Billion-Row-Challenge-Python), como um workshop, dentro do contexto educacional da Jornada de Dados, em 2024.

---

## BUSINESS PROBLEM

A seguir, destacam-se os principais problemas que esse case ajuda a resolver:

üîπ Processamento de Grandes Volumes de Dados em Arquivos Brutos.

Quando empresas frequentemente recebem dados em formatos como `.csv`, `.json` ou `.parquet` contendo milh√µes ou bilh√µes de linhas, especialmente em setores como varejo, energia, climatologia, IoT e telecom, demonstrando como ler, limpar e agregar dados diretamente de arquivos massivos, sem a necessidade imediata de carregar tudo na mem√≥ria ou depender de clusters caros.

üîπ C√°lculo Eficiente de Estat√≠sticas Agregadas.

Por meio da an√°lise de dados operacionais exige c√°lculos como m√©dia, m√°ximo e m√≠nimo, que parecem simples, mas se tornam desafiadores com grande volume e m√∫ltiplas chaves, o case mostra como aplicar estrat√©gias otimizadas de agrega√ß√£o, inclusive via DuckDB ou Pandas com chunking, simulando o c√°lculo de indicadores operacionais em escala.

üîπ Desempenho e Otimiza√ß√£o de Recursos Computacionais.

Quando projetos de dados nem sempre rodam em ambientes robustos, muitos times enfrentam limita√ß√µes de RAM, CPU e I/O, especialmente em pipelines locais, servidores intermedi√°rios ou jobs agendados, explorando estrat√©gias de baixo consumo de mem√≥ria, chunking e uso de engines colunares (como DuckDB) que permitem otimizar desempenho mesmo em m√°quinas comuns.

üîπ Valida√ß√£o de Arquiteturas Anal√≠ticas para Batch Processing.

No processo de valida√ß√£o, por exemplo, se uma arquitetura (ex: processamento local + exporta√ß√£o `.parquet`) atende aos SLAs de tempo e custo antes de mover dados para a nuvem, fornecendo um sandbox completo e replic√°vel, permitindo testar pipelines de processamento, benchmarkar formatos de arquivo e comparar abordagens de leitura e agrega√ß√£o.

üîπ Treinamento e Capacita√ß√£o T√©cnica de Times de Dados.

Para formar times com maturidade em engenharia de dados exige cases pr√°ticos e desafiadores, que v√£o al√©m de notebooks pequenos ou datasets de toy, demonstrando ser um estudo de caso avan√ßado que pode ser usado para treinar engenheiros, analistas e cientistas de dados, com foco em performance, arquitetura de dados e boas pr√°ticas de codifica√ß√£o.

üîπ Exporta√ß√£o de Dados para Consumo em BI e Visualiza√ß√µes.

Etapa comum a necessidade de transformar arquivos brutos em formatos eficientes para dashboards (como `.csv` limpo ou `.parquet` otimizado), gerando outputs padronizados e ordenados para ingest√£o por ferramentas como Power BI, Metabase, Superset ou solu√ß√µes em nuvem, com foco em consumo r√°pido e leve.

üîπ Visualiza√ß√£o Interativa com Dashboards Locais.

Al√©m do processamento eficiente, o projeto oferece um dashboard interativo constru√≠do com Streamlit, que consome os dados j√° tratados e fornece visualiza√ß√µes din√¢micas, permitindo a explora√ß√£o dos dados agregados por esta√ß√£o meteorol√≥gica. Essa visualiza√ß√£o inclui gr√°ficos de barras para temperaturas m√≠nima, m√©dia e m√°xima, al√©m de uma dispers√£o entre os extremos t√©rmicos, tudo isso com carregamento r√°pido e sem necessidade de servidores externos, cuja abordagem facilita a an√°lise explorat√≥ria local e demonstra como entregar valor anal√≠tico direto ao usu√°rio final mesmo em ambientes de infraestrutura simples.

---

## PROPOSED CHALLENGE

O desafio proposto neste projeto consiste em desenvolver uma solu√ß√£o robusta, eficiente e escal√°vel em Python capaz de processar 1 bilh√£o de registros de temperatura, simulando um ambiente real de engenharia de dados com alta volumetria. O foco est√° na extra√ß√£o de estat√≠sticas agregadas por esta√ß√£o meteorol√≥gica, com √™nfase em performance, uso consciente de recursos computacionais e entrega anal√≠tica final em m√∫ltiplos formatos, com os seguintes objetivos t√©cnicos:

üîπ Ler com efici√™ncia um arquivo de entrada contendo 1 bilh√£o de linhas, simulando medi√ß√µes massivas de sensores meteorol√≥gicos, mesmo em ambientes com recursos limitados.

üîπ Calcular estat√≠sticas agregadas por esta√ß√£o, incluindo a Temperatura m√≠nima registrada, Temperatura m√°xima registrada e Temperatura m√©dia, com precis√£o de 2 casas decimais

üîπ Ordenar os resultados alfabeticamente pelo nome da esta√ß√£o, garantindo legibilidade e estrutura anal√≠tica nos arquivos de sa√≠da.

üîπ Exportar os resultados finais em formatos amplamente utilizados `.csv` para compatibilidade com qualquer ferramenta e `.parquet` para alta performance e compress√£o eficiente

üîπ Comparar diferentes abordagens t√©cnicas, avaliando o Tempo de execu√ß√£o, o Uso de mem√≥ria RAM e o Tamanho dos arquivos gerados, tendo em norte a escalabilidade e estabilidade de cada solu√ß√£o.

Essas compara√ß√µes cobrem solu√ß√µes desde Python puro at√© DuckDB, passando por Pandas, chunking manual e PyArrow, evidenciando as vantagens, limita√ß√µes e comportamentos esperados em pipelines anal√≠ticos de larga escala.

---

### GENERAL OPERATION

A gera√ß√£o do dataset sint√©tico com 1 bilh√£o de linhas foi cuidadosamente projetada para simular condi√ß√µes realistas de ingest√£o massiva de dados sensoriais, adotando estrat√©gias eficientes de escrita e controle de performance. Abaixo, o fluxo operacional detalhado:

üîπ Valida√ß√£o dos Argumentos de Entrada
O script principal (create_measurements.py) valida se foi passado um argumento num√©rico representando a quantidade de linhas desejada (ex: 1_000_000_000), garantindo flexibilidade e controle de escala.

üîπ Coleta de Nomes de Esta√ß√µes Meteorol√≥gicas
Os nomes s√£o extra√≠dos do arquivo model.csv, contendo uma lista de localidades reais. Linhas comentadas com # s√£o ignoradas e duplicatas s√£o automaticamente removidas, garantindo um conjunto limpo de esta√ß√µes v√°lidas.

üîπ Estimativa de Tamanho do Arquivo Final
Antes de iniciar a gera√ß√£o, o sistema calcula uma estimativa de espa√ßo em disco com base na quantidade de esta√ß√µes, na m√©dia de caracteres por linha e no formato do dado, auxiliando no planejamento de infraestrutura.

üîπ Gera√ß√£o Sint√©tica de Temperaturas Aleat√≥rias
Para cada linha, √© atribu√≠da uma temperatura float entre -99.9¬∞C e 99.9¬∞C, simulando leituras sensoriais, a sele√ß√£o das esta√ß√µes segue distribui√ß√£o uniforme com random.choices().

üîπ Escrita do Arquivo data/weather_stations.csv
As medi√ß√µes s√£o geradas em lotes e salvas diretamente em disco no formato delimitado por ponto e v√≠rgula (;), o nome da esta√ß√£o e a temperatura s√£o armazenados por linha, mantendo consist√™ncia e portabilidade.

üîπ Processamento em Batches (100 Milh√µes por Lote)
A escrita √© realizada em blocos de 100_000_000 registros por vez, reduzindo o impacto de I/O e melhorando drasticamente a performance de grava√ß√£o, uma barra de progresso (tqdm) exibe o avan√ßo da gera√ß√£o.

üîπ Monitoramento e Medi√ß√£o de Performance
Ao final da execu√ß√£o, o script exibe o tempo total decorrido e o tamanho real do arquivo gerado, validando a estimativa inicial e permitindo benchmarking do processo.

---

### OUTPUT FILE

Arquivo gerado `data/weather_stations.csv` em 6 min e 5 seg, com 14.8 GiB, somando 1 bilh√£o de linhas, com nome_da_esta√ß√£o `string` e temperatura `float` com precis√£o de duas casas decimais

```text
<nome_da_esta√ß√£o>;<temperatura>
```

Exemplo:

```text
Stockholm;-5.32
S√£o Paulo;25.85
Cape Town;19.01
```
---

### INTERESTING TECHNICAL POINTS

Durante o desenvolvimento deste projeto, diversas boas pr√°ticas de engenharia de dados foram aplicadas, aliando performance, clareza e adaptabilidade. Desde a gera√ß√£o de dados at√© as estrat√©gias de leitura e processamento, cada etapa foi pensada para refletir desafios reais enfrentados por engenheiros de dados em ambientes com recursos limitados.

A gera√ß√£o do arquivo de 1 bilh√£o de linhas evitou o uso do `round()` tradicional, optando por interpola√ß√£o de strings `(f"{x:.1f}")` para controlar casas decimais com melhor desempenho, ainda, distribui√ß√£o dos nomes das esta√ß√µes meteorol√≥gicas foi feita com `random.choices()` para simular uniformidade geogr√°fica realista, a escrita dos dados foi realizada em blocos (batch write), reduzindo drasticamente o tempo de I/O, uma otimiza√ß√£o essencial quando se trabalha com arquivos massivos.

Antes mesmo da gera√ß√£o dos dados, o script realiza uma estimativa precisa do tamanho esperado em disco, auxiliando no planejamento de infraestrutura. Ao longo da execu√ß√£o, mensagens informativas e uma barra de progresso mant√™m o usu√°rio bem informado, com valida√ß√µes robustas e op√ß√µes de ajuda acess√≠veis por linha de comando.

Na etapa de processamento, diferentes abordagens foram implementadas para comparar desempenho, escalabilidade e consumo de mem√≥ria, desde leitura linha a linha com agrega√ß√µes em tempo real em dicion√°rios (ideal para m√°quinas com pouca RAM), at√© chunking manual e com Pandas, permitindo maior controle e performance em pipelines iterativos.

Tamb√©m foi inclu√≠do o uso do DuckDB, uma engine colunar embutida que executa consultas SQL diretamente sobre arquivos `.csv` e `.parquet`, entregando performance pr√≥xima de sistemas distribu√≠dos, mas sem a complexidade de um cluster.

Essa combina√ß√£o de t√©cnicas oferece um estudo de caso valioso para quem busca aprender ou ensinar pr√°ticas reais de engenharia de dados com foco em desempenho, boas escolhas arquiteturais e dom√≠nio t√©cnico sobre o stack Python moderno.

---

## HOW TO RUN

### REQUIREMENTS

1. Git e Github: Utilizado para versionamento do c√≥digo e para reposit√≥rio remoto do projeto.
Voc√™ deve ter o Git instalado em sua m√°quina e tamb√©m deve ter uma conta no GitHub.
[Instru√ß√µes de instala√ß√£o do Git aqui](https://git-scm.com/doc).
[Instru√ß√µes de instala√ß√£o do Github aqui](https://docs.github.com/pt).

2. Pyenv: √â usado para gerenciar vers√µes do Python em ambientes virtuais, fundamental para isolar a aplica√ß√£o e evitar problemas de conflitos entre vers√µes de bibliotecas e do pr√≥prio Python.
[Instru√ß√µes de instala√ß√£o do Pyenv aqui](https://github.com/pyenv/pyenv#installation).
Neste projeto, vamos utilizar o Python 3.11.4

3. Poetry: Este projeto utiliza Poetry para gerenciamento de depend√™ncias.
[Instru√ß√µes de instala√ß√£o do Poetry aqui](https://python-poetry.org/docs/#installation).

---

### INSTALA√á√ÉO E CONFIGURA√á√ÉO

A - No diret√≥rio raiz, execute o comando, passando os argumentos da quantidade de linhas que quer gerar:

```python
python create_measurements.py 1_000_000_000
```
---

B - Confirmar a quantidade de linhas e o formato do arquivo gerado:
```python
wc -l ../data/weather_stations.csv
head -n 5 ../data/weather_stations.csv
```

C - Acesse o diret√≥rio `src` e execute os comandos abaixo, de acordo com a ferramenta e amodelagem de dados desejada:

1) Python - processamento BRUTO, utilizando `defaultdict`, Python vanilla!
```python
python etl_python.py
```

2) Python com chuncking
```python
python etl_python_chuncking.py
```

3) Instale a biblioteca Pyarrow, utilizando o Poetry, com o comando:
```python
poetry add pyarrow
```

4) Python com Pyarrow
```python
python etl_python_pyarrow.py
```

5) Instale a biblioteca Pandas, utilizando o Poetry, com o comando:
```python
poetry add pandas
```

6) Pandas
```python
python etl_pandas.py
```

7) Pandas com chuncking
```python
python etl_pandas_chuncking.py
```

8) Instale a biblioteca Polars, utilizando o Poetry, com o comando:
```python
poetry add polars
```

9) Polars
```python
python etl_polars.py
```

10)  Instale a biblioteca DuckDB, utilizando o Poetry, com o comando:
```python
poetry add duckdb
```

11)  DuckDB
```python
python etl_duckdb.py
```
### LOGGING

Todos os processamentos est√£o sendo gravados no diret√≥rio `logs`com seu respectivo nome do arquivo.

---

## OUTPUT EXAMPLES

Todos os resultados finais s√£o exportados nos formatos `.csv` e `.parquet` .

Isso permite an√°lises posteriores em ferramentas como Power BI, Metabase, Apache Superset ou puro Python, inclusive, o arquivo de sa√≠da ser√° ordenado alfabeticamente por nome da esta√ß√£o:

```python
| Esta√ß√£o    |   Min  | M√©dia |  Max  |
| ---------- | ------ | ----- | ----- |
| Aabenraa   | -99.80 | 3.4   | 99.80 |
| Bariloche  | -57.40 | 8.2   | 87.30 |
| Copenhagen | -45.50 | 11.9  | 94.10 |
```

---

## BENCHMARKING AND PERFORMANCE RESULTS ‚ú®

### PYTHON
üî¥ Python vanilla, sem utiliza√ß√£o de ulimit ou cgroups, a ETL quebrou por 6 vezes, consumindo os 16 GiB (15.3) de mem√≥ria RAM do servidor e mais 4 de Swp.

üü® Python Vanilla com melhorias de performance, a ETL rodou satisfatoriamente, demorando 726.20 segundos (pouco mais de 12 minutos) e consumindo apenas 1.5 GiB de mem√≥ria RAM, no momento de pico de utiliza√ß√£o do sistema.

üü® Python com a utiliza√ß√£o de t√©cnica de chunking, a ETL rodou sofrida, n√£o aguentou com chuncking de 100 milh√µes de linhas, quebrando duas vezes, rodando com chuncking de 50 milh√µes de linhas em 20 etapas, demorando 1436.41 segundos (quase 24 minutos) e consumindo 12.2 GiB de mem√≥ria RAM, no momento de pico de utiliza√ß√£o do sistema.

---

### PYTHON + PYARROW
üü® Python com a utiliza√ß√£o da biblioteca pyarrow apenas para gravar o parquet, a ETL rodou satisfatoriamente, demorando 711.31 segundos (quase 12 minutos) e consumindo apenas 1.2 GiB de mem√≥ria RAM, no momento de pico de utiliza√ß√£o do sistema.

---

### PYTHON + PANDAS
üî¥ Python + Pandas na leitura e no processamento, a ETL quebrou por 3 vezes, consumindo os 16 GiB (15.3) de mem√≥ria RAM do servidor e mais 4 de Swp.

üü® Python + Pandas na leitura e no processamento + utiliza√ß√£o de t√©cnica de chunking, a ETL rodou satisfatoriamente, rodou com chuncking de 100 milh√µes de linhas, demorando 348.58 segundos (quase 6 minutos) e consumindo 10 GiB de mem√≥ria RAM, no momento de pico de utiliza√ß√£o do sistema.

---

### PYTHON + POLARS
üî¥ Python + Polars na leitura e no processamento, a ETL quebrou por 3 vezes, em 5 segundos, consumindo os 16 GiB (15.3) de mem√≥ria RAM do servidor e mais 4 de Swp.

üî¥ Python + Polars na leitura e no processamento + utiliza√ß√£o de t√©cnica de paralelismo, a ETL quebrou por 3 vezes, em 5 segundos, consumindo os 16 GiB (15.3) de mem√≥ria RAM do servidor e mais 4 de Swp.

---

### DuckDB ü•á üèÜ
üü¢ Utiliza√ß√£o do banco de dados DuckDB, a ETL rodou lisa, demorando 12.38 segundos e consumindo apenas 1.76 GiB de mem√≥ria RAM, no momento de pico de utiliza√ß√£o do sistema.

Durante o desenvolvimento do desafio, foi instalado recurso Early Out-Of-Memory killer, que monitora a mem√≥ria do sistema e mata processos automaticamente antes que o sistema fique totalmente sem mem√≥ria (e congele), previnindo travamentos causados por falta de RAM, especialmente √∫til em sistemas com pouca mem√≥ria, como homelabs.

## CONCLUSION

O benchmark conduzido com 1 bilh√£o de registros sint√©ticos de esta√ß√µes meteorol√≥gicas revela insights importantes sobre tempo de execu√ß√£o, uso de mem√≥ria, tamanho dos arquivos e escalabilidade entre diferentes estrat√©gias de processamento: Python puro, Pandas, abordagens com chunking, Polars e DuckDB.

### 1. Tempo de Execu√ß√£o Total

- DuckDB manteve seu desempenho superior, concluindo a ETL em apenas 12.38 segundos, mesmo com 1 bilh√£o de linhas.
- Pandas com chunking foi a abordagem tradicional mais eficiente, concluindo em 348.58 segundos (~6 minutos).
- Python puro com melhorias levou 726.20 segundos (~12 minutos), com performance est√°vel.
- Python com chunking precisou de m√∫ltiplas etapas (20 chunks de 50 milh√µes), totalizando 1436.41 segundos (~24 minutos).
- As abordagens com Polars e Pandas sem chunking falharam devido ao estouro de mem√≥ria, n√£o completando a execu√ß√£o.

![total_time](image.png)

---

### 2. Pico de Uso de Mem√≥ria RAM

- Python + PyArrow (escrevendo apenas Parquet com PyArrow) foi o mais econ√¥mico, com pico de 1.2 GiB.
- DuckDB tamb√©m se manteve enxuto, consumindo apenas 1.76 GiB.
- Python + melhorias estabilizou em 1.5 GiB.
- Pandas com chunking usou 10 GiB, demonstrando bom controle.
- Python com chunking chegou a 12.2 GiB.
- Pandas, Polars e outras abordagens sem chunking estouraram os 16 GiB de RAM + 4 GiB de swap, travando a execu√ß√£o.

![total_memory](image-1.png)

---

### 3. Tamanho dos Arquivos (MiB)

Todos os arquivos CSV t√™m tamanho semelhante (~252 KB), o DuckDB gerou o menor `.csv` e tamb√©m o `.parquet` mais compacto, evidenciando compress√£o eficiente e escrita otimizada.

![total_file_size](image-2.png)

---

### Considera√ß√µes de Arquitetura e Escalabilidade

- DuckDB permanece como a op√ß√£o mais r√°pida, leve e escal√°vel para an√°lise local, com excelente performance mesmo com 1 bilh√£o de registros.
- Pandas + chunking se mostra um bom compromisso para ambientes com restri√ß√£o de mem√≥ria, sem comprometer robustez.
- Python puro com chunking √© funcional, mas requer ajustes e monitoramento rigoroso de recursos.
- Polars ainda n√£o sustentou o volume testado, falhou em todas as tentativas mesmo com paralelismo ativado.

### Recomenda√ß√µes Finais

Para pipelines de grande volume com baixa complexidade de transforma√ß√£o e foco em performance:

- ‚úÖ DuckDB continua imbat√≠vel: r√°pido, econ√¥mico e com boa compress√£o.
- üü° Pandas com chunking √© seguro, compat√≠vel e f√°cil de manter.
- üü° Python com chunking √© defens√°vel, mas exige mais trabalho manual.
- üî¥ Abordagens sem chunking n√£o s√£o recomendadas acima de 1 bilh√£o de linhas.
- ‚û°Ô∏è DuckDB √© a escolha mais enxuta, tanto em CSV quanto em Parquet.
- ‚û°Ô∏è Parquet √© amplamente superior ao CSV em termos de efici√™ncia de armazenamento e preparo para an√°lise.

---

## Funcionalidades do Dashboard

Dashboard interativo em Streamlit exibe e explora estat√≠sticas clim√°ticas agregadas por esta√ß√£o meteorol√≥gica e as principais funcionalidades incluem:

### Leitura e Visualiza√ß√£o de Dados

- Leitura otimizada de arquivo `.csv` com separador `;`.
- Verifica√ß√£o autom√°tica da exist√™ncia do arquivo de dados.
- Exibi√ß√£o interativa da tabela completa com estat√≠sticas por esta√ß√£o.
- Feedback visual de sucesso ou erro no carregamento dos dados.


### Visualiza√ß√µes Gr√°ficas Interativas

1.  Temperatura M√©dia por Esta√ß√£o, com gr√°fico de barras com valores m√©dios por esta√ß√£o.
2.  Temperatura M√≠nima por Esta√ß√£o, por meio de gr√°fico de barras colorido com escala azul para destacar varia√ß√µes de m√≠nimas.
3.  Temperatura M√°xima por Esta√ß√£o, utilizando gr√°fico de barras com colora√ß√£o em tons de vermelho para destacar extremos.
4.  E dispers√£o de M√≠nima vs M√°xima, com gr√°fico de dispers√£o (scatter plot) com cada ponto representando uma esta√ß√£o.
    - Eixo X: Temperatura m√≠nima
    - Eixo Y: Temperatura m√°xima
    - Tamanho dos pontos baseado na temperatura m√©dia (normalizada)

### Como rodar o dashboard

O reposit√≥rio contempla o arquivo `src/create_station_metrics_mart.py` que gera um arquivo intermedi√°rio `data/station_metrics_mart.csv` , transformado e preparado para consumo do dashboard que pode ser executado, por meio dos comandos:

1) Instale a biblioteca Streamlit, utilizando o Poetry, com o comando:
```python
poetry add streamlit
```

2) no diret√≥rio `dashboard`, execute o Streamlit:
```python
poetry run streamlit run dashboard/app_duckdb_csv_table.py
```
3) Acesse a url fornecida pela aplica√ß√£o.

---

## ‚ú® ü¶Ü O DuckDB √© t√£o excepcional que merece uma explica√ß√£o um pouco mais detalhada


### DuckDB: r√°pido, leve e pronto para escalar localmente

DuckDB √© uma excelente fonte para dashboards, se usado da maneira certa, o motor mais equilibrado para an√°lises locais e pipelines de pequeno e m√©dio porte, por que funciona t√£o bem?

- Ele processa os dados direto do disco, sem precisar carreg√°-los inteiramente na mem√≥ria.
- Seu modelo de execu√ß√£o √© colunar e vetorizado, o que significa que cada opera√ß√£o trabalha por blocos otimizados, aproveitando o cache do processador.
- Funciona bem mesmo com apenas um n√∫cleo (monothread), o que o torna ideal para ambientes simples, como notebooks ou servidores de uso geral.
- Leitura muito r√°pida:
- Consultas anal√≠ticas (`SELECT`, `GROUP BY`, `JOIN`) s√£o extremamente otimizadas em DuckDB, principalmente em formatos como Parquet e CSV.
- Ideal para pain√©is que consultam dados prontos, agregados.
- Compat√≠vel com ODBC/ODBC-like connectors:
- DuckDB oferece conectores (em evolu√ß√£o) para se integrar com BI tools, especialmente via drivers ODBC.
- J√° existem m√©todos para conectar o Power BI via ODBC e o Metabase via JDBC/ODBC (com algum esfor√ßo).
- Formato leve e port√°til:
- O `.DuckDB` √© um √∫nico arquivo. Voc√™ pode gerar e compartilhar com o dashboard, sem precisar de um servidor de banco.
- Integra√ß√£o com Parquet e CSV:
- DuckDB pode ser usado para consultar diretamente arquivos Parquet/CSV como se fossem tabelas, √∫til quando seu dashboard √© alimentado por arquivos externos.

‚úÖ Ideal para prot√≥tipos r√°pidos e ETLs locais com performance real, ambientes com pouca RAM ou CPU.

---

############################### MAS CUIDADO ‚õî ###############################

---

O DuckDB √© uma ferramenta poderosa, mas como toda tecnologia, tem um conjunto de casos para os quais √© ideal e outros onde n√£o √© a melhor escolha, conforme segue:

### ‚ö†Ô∏è DuckDB √© excelente para prototipagem, an√°lise local, cargas moderadas e dados tabulares em formato Parquet, CSV, Arrow, mas por que DuckDB n√£o √© geralmente indicado para produ√ß√£o?

Nem todo projeto de dados exige alta performance ou infraestrutura distribu√≠da, mas saber escolher a abordagem certa para o contexto certo √© o que separa scripts r√°pidos de pipelines confi√°veis e sustent√°veis, seus testes mostraram que cada tecnologia se comporta de forma distinta frente a tr√™s fatores cr√≠ticos: volume de dados, disponibilidade de mem√≥ria RAM e necessidade de escalabilidade.

#### 1. Arquitetura embutida, n√£o cliente-servidor

- DuckDB roda embutido no processo da aplica√ß√£o (embedded database), isso quer dizer que n√£o h√° um servidor separado para lidar com concorr√™ncia, autentica√ß√£o, escalabilidade, etc., em produ√ß√£o, espera-se que o banco aceite m√∫ltiplas conex√µes, distribua carga e possa ser escalado horizontalmente.

üëâ Consequ√™ncia: DuckDB √© monousu√°rio por design, se m√∫ltiplas aplica√ß√µes ou usu√°rios tentarem acessar o mesmo banco simultaneamente, voc√™ corre risco de corrup√ß√£o ou race conditions.

---

#### 2. N√£o suporta m√∫ltiplas sess√µes concorrentes de escrita

- Em bancos como PostgreSQL, m√∫ltiplos processos podem ler e escrever simultaneamente, com controle de transa√ß√µes.
- O DuckDB s√≥ permite uma escrita por vez e ainda bloqueia arquivos `.DuckDB` durante a opera√ß√£o.

üëâ Consequ√™ncia: Impratic√°vel em ambientes multiusu√°rio, com alta taxa de grava√ß√£o ou uso concorrente, como APIs, microsservi√ßos e sistemas OLTP.

---

#### 3. N√£o √© tolerante a falhas por padr√£o

- Bancos de produ√ß√£o geralmente contam com replica√ß√£o, backups autom√°ticos, failover, logs de transa√ß√£o para recovery e DuckDB n√£o implementa esses recursos nativamente.

üëâ Consequ√™ncia: Se seu processo for interrompido abruptamente (por crash, falha de disco ou interrup√ß√£o de energia), voc√™ pode perder o banco ou corromper o arquivo.

---

#### 4. N√£o escala horizontalmente

- DuckDB n√£o possui arquitetura distribu√≠da, ele n√£o foi feito para escalar em m√∫ltiplas m√°quinas nem processar grandes volumes em cluster (como Spark, Dask, BigQuery, etc).

üëâ Consequ√™ncia: Para dados de alta volumetria (> bilh√µes de linhas), ou para times que precisam escalar a leitura e escrita em paralelo, o DuckDB n√£o acompanha.

---

#### 5. Foco principal √© an√°lise local ‚Äî OLAP, n√£o OLTP

- DuckDB √© orientado a consultas anal√≠ticas complexas (OLAP), n√£o a sistemas transacionais (OLTP), ele brilha ao fazer `SELECT station, AVG(temp)` em 100 milh√µes de linha, mas n√£o serve bem para registrar pedidos de e-commerce ou gerenciar usu√°rios de um app em tempo real.

üëâ Consequ√™ncia: N√£o use DuckDB para aplica√ß√µes com alta taxa de inser√ß√£o, atualiza√ß√£o ou leitura em tempo real.

---

### Use DuckDB com confian√ßa para:

![alt text](image-5.png)

Quando se trata de uso do DuckDB como fonte de dados para dashboards, como Power BI, Metabase, Superset ou at√© Streamlit, a an√°lise muda bastante, e a resposta √© "depende do uso, mas com ressalvas importantes".

---

### Recomenda√ß√µes pr√°ticas
![DuckDB](image-4.png)

DuckDB √© extremamente eficaz para gerar datasets anal√≠ticos e alimentadores de dashboard, mas n√£o √© ideal como fonte de dados din√¢mica e concorrente.

- Use DuckDB para processar e entregar dados prontos para visualiza√ß√£o.
- Evite us√°-lo como backend direto em dashboards multiusu√°rio em produ√ß√£o.
- Melhor estrat√©gia: DuckDB ‚Üí Parquet ‚Üí Dashboard.

---

## MAIN TECHNICAL FEATURES

‚úÖ Processamento de 1 bilh√£o de registros (~14GB) com m√∫ltiplas abordagens: Python puro, Pandas, chunking manual, PyArrow, Polars e DuckDB.

‚úÖ Benchmark completo avaliando tempo de execu√ß√£o, uso de mem√≥ria e tamanho de arquivos de sa√≠da (`.csv` e `.parquet`).

‚úÖ Gera√ß√£o realista de dados sint√©ticos, com distribui√ß√£o uniforme entre esta√ß√µes meteorol√≥gicas e varia√ß√£o controlada de temperatura.

‚úÖ Chunking com controle de mem√≥ria, permitindo processar arquivos massivos sem sobrecarregar a RAM.

‚úÖ Uso avan√ßado do DuckDB, engine anal√≠tica colunar SQL-in-process, com leitura direta do disco e escrita compacta.

‚úÖ Visualiza√ß√£o e storytelling anal√≠tico com gr√°ficos comparativos de tempo, mem√≥ria e espa√ßo.

‚úÖ Script modular em Python, com logging, organiza√ß√£o em camadas (src/, data/, logs/) e suporte a m√∫ltiplos formatos.

‚úÖ Ambiente isolado com Pyenv e Poetry, garantindo reprodutibilidade e controle de depend√™ncias.

‚úÖ Padr√µes de codifica√ß√£o e seguran√ßa com pre-commit hooks, linting (ruff, black) e auditoria de depend√™ncias (pip-audit).

‚úÖ Foco educacional e de portf√≥lio, com documenta√ß√£o detalhada, orientada √† performance, arquitetura e boas pr√°ticas.

---

## TECHNOLOGIES USED

### üõ†Ô∏è Project Stack Challenge Overview

![stack](image-6.png)


### Tecnologias Utilizadas no Dashboard

- Streamlit: Framework web para dashboards em Python.
- Plotly Express: Gr√°ficos interativos com visual moderno.
- Pandas: Leitura e manipula√ß√£o de dados tabulares.
- Pathlib: Manipula√ß√£o segura de caminhos de arquivos.
---

## QUESTIONS, SUGGESTIONS OR FEEDBACK

üöÄ Andr√© Matiello C. Caramanti - [matiello.andre@hotmail.com](mailto:matiello.andre@hotmail.com)

Project carried out with the support of Artificial Intelligence (ChatGPT)

---

## LICENSE

[MIT License](https://andrematiello.notion.site/mit-license)
